{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LogNorm\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import pandas as pd\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "import re\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b224c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained('../../models/llama-7b-hf', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b1a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'\\d+', filename)\n",
    "    return int(match.group()) if match else float('inf')\n",
    "\n",
    "def sort_files(activations_directory):\n",
    "  activation_folder_list = os.listdir(activations_directory)\n",
    "  activation_folder_list = sorted(activation_folder_list, key=extract_number, reverse=False)\n",
    "  return activation_folder_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb5d7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming a data set with variable length tokens, token_output_focus determines which token to focus on for each element of the data set\n",
    "# Assumes filename corresponds to the class of the prompt\n",
    "def build_activations_array(activations_directory, activation_folder_list, token_output_focus = \"first\", first_n_files=None):\n",
    "  if first_n_files is None:\n",
    "    first_n_files = len(activation_folder_list)\n",
    "\n",
    "  # Array of arrays \n",
    "  all_prompt_activations = [] \n",
    "  all_prompt_filenames = []\n",
    "  all_prompt_tokens = []\n",
    "\n",
    "  # Load the CSV file into a pandas DataFrame\n",
    "  df = pd.read_csv(activations_directory+'Task.csv')\n",
    "\n",
    "  # Create a dictionary that maps question IDs to classes\n",
    "  id_to_class = df.set_index('Question_ID')['Class'].to_dict()\n",
    "  id_to_q_type = df.set_index('Question_ID')['Question_Type'].to_dict()\n",
    "#   print(id_to_class)\n",
    "#   print(id_to_q_type)\n",
    "\n",
    "  activation_folder_list = [f for f in activation_folder_list if os.path.splitext(f)[1] == '.pt']\n",
    "\n",
    "  for activation_file in tqdm((activation_folder_list[:first_n_files]), position=0, leave=True):\n",
    "      # Extract the question ID from the filename\n",
    "      question_id = int(re.search(r\"^Question_(\\d+)_\", activation_file).group(1))\n",
    "      \n",
    "      # Check if the question type is 'character_qa_close' before proceeding\n",
    "      if id_to_q_type[question_id] == 'character_qa_close':\n",
    "#       if 1:\n",
    "#           Use the dictionary to get the corresponding class\n",
    "\n",
    "          activation_path = os.path.join(activations_directory,str(activation_file))\n",
    "          data = torch.load(activation_path, map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "          hidden_states = data['hidden_states']\n",
    "          output_response = data['output'].split(\"Response:\")[1]\n",
    "          tokenized_output_response = tokenizer.encode(output_response)\n",
    "\n",
    "          \n",
    "\n",
    "          if token_output_focus == \"first\":\n",
    "            token_id = 3 # Disregard first hidden state (which inclued all input? tokens), and disregard first two tokens (['', '<0x0A>',)\n",
    "          if token_output_focus == \"last\":\n",
    "              token_id = len(hidden_states) - 1\n",
    "              token_text = tokenizer.decode(tokenized_output_response[token_id])\n",
    "#               Check if token_text is not one of the specified strings\n",
    "              if token_text not in [\"Yes\", \"yes\", \"No\", \"no\"]:\n",
    "                  token_id = len(hidden_states) - 2 # n-1 to avoid full stop\n",
    "                  token_text = tokenizer.decode(tokenized_output_response[token_id])\n",
    "                  if token_text not in [\"Yes\", \"yes\", \"No\", \"no\"]:\n",
    "                    print(\"output neither yes or no\")\n",
    "                    continue\n",
    "\n",
    "#           filename = id_to_class[question_id] +'_'+ id_to_q_type[question_id]+'_'+token_text\n",
    "          filename = id_to_class[question_id]\n",
    "          all_prompt_filenames.append(filename)\n",
    "          \n",
    "          token_hidden_states = hidden_states[token_id]\n",
    "\n",
    "          # Initialize an empty dictionary to store activations\n",
    "          activations = []\n",
    "\n",
    "          # iterate through all layers for each token's hidden states\n",
    "          for layer_id, layers in enumerate(token_hidden_states):\n",
    "            # print(\"Layer: \"+str(layer_id))\n",
    "            for beam_id, beams in enumerate(layers):\n",
    "              # print(\"Beam: \"+str(beam_id))\n",
    "              for token_activation_id, token_activations in enumerate(beams):\n",
    "                # print(token_activations.shape)\n",
    "                token_activations_np = token_activations.numpy()  # Detach and convert to NumPy array\n",
    "                activations.extend(token_activations_np)\n",
    "          token_text = tokenizer.decode(tokenized_output_response[token_id])\n",
    "          all_prompt_activations.append(activations)\n",
    "          all_prompt_tokens.append(token_text)\n",
    "\n",
    "  return all_prompt_activations, all_prompt_filenames, all_prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05949362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:14<00:00, 53.89it/s]\n"
     ]
    }
   ],
   "source": [
    "activations_directory = \"/home/gridsan/wzulfikar/activations/dataset_trex/\"\n",
    "#Sort files\n",
    "activation_folder_list = sort_files(activations_directory)\n",
    "#Set params\n",
    "token_output_focus = \"last\"\n",
    "first_n_files = 800\n",
    "\n",
    "all_prompt_activations, all_prompt_filenames, all_prompt_tokens = build_activations_array(activations_directory, activation_folder_list, token_output_focus = token_output_focus, first_n_files = first_n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d306ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Lovelace\n",
      "Vincent Van Gogh\n",
      "Princess Leia\n",
      "William Shakespeare\n",
      "Albert Einstein\n",
      "Sherlock Holmes\n",
      "Marie Curie\n",
      "Harry Potter\n",
      "Lady Gaga\n",
      "Isaac Newton\n",
      "Barney the Dinosaur\n",
      "Socrates\n",
      "Cleopatra\n",
      "Hermione Granger\n"
     ]
    }
   ],
   "source": [
    "unique_strings = set(all_prompt_filenames)\n",
    "\n",
    "for unique_string in unique_strings:\n",
    "    print(unique_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63d75080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209920, 379)\n",
      "(379, 14)\n"
     ]
    }
   ],
   "source": [
    "clustering_data = np.array(all_prompt_activations).T\n",
    "target = np.array(all_prompt_filenames)[:, np.newaxis]\n",
    "target = OneHotEncoder().fit_transform(target)\n",
    "\n",
    "print(clustering_data.shape)\n",
    "print(target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "240372c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Ada Lovelace', 'Vincent Van Gogh', 'Princess Leia', 'William Shakespeare', 'Albert Einstein', 'Sherlock Holmes', 'Marie Curie', 'Harry Potter', 'Lady Gaga', 'Isaac Newton', 'Barney the Dinosaur', 'Socrates', 'Cleopatra', 'Hermione Granger'])\n"
     ]
    }
   ],
   "source": [
    "classes = set(all_prompt_filenames)\n",
    "all_prompt_activations_with_class = {k:[] for k in classes}\n",
    "for j, activation in enumerate(all_prompt_activations):\n",
    "    k = all_prompt_filenames[j]\n",
    "    all_prompt_activations_with_class[k].append(np.array(activation))\n",
    "\n",
    "print(all_prompt_activations_with_class.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f6e96",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e55f837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 13.812620401382446\n"
     ]
    }
   ],
   "source": [
    "from cuml.manifold.umap import UMAP as cumlUMAP\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "cuml_umap = cumlUMAP(n_components=2, n_neighbors=16, init=\"spectral\")\n",
    "embedding = cuml_umap.fit_transform(clustering_data)\n",
    "print(\"Time taken\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "127fb268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209920, 2)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41deee1d",
   "metadata": {},
   "source": [
    "## K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef8892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209920 379\n",
      "Fitting\n",
      "Time taken  0.3917968273162842\n"
     ]
    }
   ],
   "source": [
    "# Assuming embedding is your data and its shape is [n_neurons, features]\n",
    "# n_neurons = embedding.shape[0]\n",
    "# features = embedding.shape[1]\n",
    "import cudf\n",
    "import cuml\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "embedding = clustering_data\n",
    "\n",
    "n_neurons = embedding.shape[0]\n",
    "features = embedding.shape[1]\n",
    "print(n_neurons, features)\n",
    "\n",
    "# Convert your data to cuDF DataFrame, because cuML works with cuDF DataFrame\n",
    "df = cudf.DataFrame(embedding, columns=[f'feature_{i+1}' for i in range(features)])\n",
    "\n",
    "# Initialize the KMeans model\n",
    "kmeans = cuml.KMeans(n_clusters=16)\n",
    "\n",
    "print(\"Fitting\")\n",
    "# Fit the model\n",
    "kmeans.fit(df)\n",
    "\n",
    "# Get cluster predictions\n",
    "df['cluster'] = kmeans.predict(df)\n",
    "\n",
    "print(\"Time taken \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6504a794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       dtype=int32),\n",
       " array([    33,     33, 119558,     33,     33,      7,     66,     79,\n",
       "            33,    280,    261,      7,     21,     50,  44537,  44889]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(kmeans.labels_.to_numpy(), return_counts=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9a76eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming embedding is your data and its shape is [n_neurons, features]\n",
    "# # n_neurons = embedding.shape[0]\n",
    "# # features = embedding.shape[1]\n",
    "# import cudf\n",
    "# import cuml\n",
    "\n",
    "# n_neurons = embedding.shape[0]\n",
    "# features = 2\n",
    "\n",
    "# # Convert your data to cuDF DataFrame, because cuML works with cuDF DataFrame\n",
    "# df = cudf.DataFrame(embedding, columns=[f'feature_{i+1}' for i in range(features)])\n",
    "\n",
    "# # Initialize the KMeans model\n",
    "# kmeans = cuml.KMeans(n_clusters=16)\n",
    "\n",
    "# print(\"Fitting\")\n",
    "# # Fit the model\n",
    "# kmeans.fit(df)\n",
    "\n",
    "# # Get cluster predictions\n",
    "# df['cluster'] = kmeans.predict(df)\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# for i in range(16):\n",
    "#     cluster_data = df[df['cluster'] == i].to_pandas()\n",
    "#     plt.scatter(cluster_data['feature_1'], cluster_data['feature_2'], label=f'Cluster {i+1}')\n",
    "\n",
    "# plt.title('KMeans Clustering with cuML')\n",
    "# plt.xlabel('Feature 1')\n",
    "# plt.ylabel('Feature 2')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19c95ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class Ada Lovelace, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 7026.3781174879805\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 3171.427283653846\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 1210.3545673076924\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 76.16211964533879\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 22.863487830528847\n",
      "\n",
      "For class Vincent Van Gogh, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 4658.08642578125\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 2101.1958512931033\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 800.3592403017242\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 50.432722420528016\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 15.289070918642242\n",
      "\n",
      "For class Princess Leia, the top 5 clusters are:\n",
      "Cluster ID: 0, Number of neurons: 4, Mean activation: 107.77678571428571\n",
      "Cluster ID: 12, Number of neurons: 4, Mean activation: 75.57589285714286\n",
      "Cluster ID: 10, Number of neurons: 6, Mean activation: 31.936941964285715\n",
      "Cluster ID: 6, Number of neurons: 33, Mean activation: 9.826729910714286\n",
      "Cluster ID: 7, Number of neurons: 19, Mean activation: 6.2294921875\n",
      "\n",
      "For class William Shakespeare, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 2356.013545283565\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 1058.4409722222222\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 401.8716724537037\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 25.165156611689813\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 7.965015552662037\n",
      "\n",
      "For class Albert Einstein, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 1415.2682059151787\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 632.2024274553571\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 239.05287388392858\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 15.097393580845424\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 4.879708426339286\n",
      "\n",
      "For class Sherlock Holmes, the top 5 clusters are:\n",
      "Cluster ID: 0, Number of neurons: 4, Mean activation: 110.50669642857143\n",
      "Cluster ID: 12, Number of neurons: 4, Mean activation: 77.76339285714286\n",
      "Cluster ID: 10, Number of neurons: 6, Mean activation: 32.776785714285715\n",
      "Cluster ID: 6, Number of neurons: 33, Mean activation: 9.402064732142858\n",
      "Cluster ID: 7, Number of neurons: 19, Mean activation: 6.2568359375\n",
      "\n",
      "For class Marie Curie, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 5574.891131365741\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 2514.814525462963\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 959.2326388888889\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 60.65907457139757\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 18.248119212962962\n",
      "\n",
      "For class Harry Potter, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 2833.938319614955\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 1274.9077845982142\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 484.69503348214283\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 30.815879821777344\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 9.452427455357142\n",
      "\n",
      "For class Lady Gaga, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 1365.4401434536637\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 610.7758620689655\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 229.9286099137931\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 14.951585046176252\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 4.789214035560345\n",
      "\n",
      "For class Isaac Newton, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 6468.263138382523\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 2919.212384259259\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 1114.5015914351852\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 70.23642758969908\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 21.14703595196759\n",
      "\n",
      "For class Barney the Dinosaur, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 415.14712685032896\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 180.97203947368422\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 65.88671875\n",
      "Cluster ID: 0, Number of neurons: 4, Mean activation: 64.11842105263158\n",
      "Cluster ID: 12, Number of neurons: 4, Mean activation: 39.54934210526316\n",
      "\n",
      "For class Socrates, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 271.48709527377423\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 113.96390086206897\n",
      "Cluster ID: 0, Number of neurons: 4, Mean activation: 86.74353448275862\n",
      "Cluster ID: 12, Number of neurons: 4, Mean activation: 59.786637931034484\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 40.322737068965516\n",
      "\n",
      "For class Cleopatra, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 1465.1122504340278\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 654.4409722222222\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 246.91869212962962\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 15.784195511429399\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 5.1137514467592595\n",
      "\n",
      "For class Hermione Granger, the top 5 clusters are:\n",
      "Cluster ID: 2, Number of neurons: 33, Mean activation: 4412.897180627893\n",
      "Cluster ID: 5, Number of neurons: 33, Mean activation: 1990.1494502314815\n",
      "Cluster ID: 4, Number of neurons: 33, Mean activation: 757.9252025462963\n",
      "Cluster ID: 9, Number of neurons: 139, Mean activation: 47.696247807255496\n",
      "Cluster ID: 15, Number of neurons: 1555, Mean activation: 14.520878544560185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cuml\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_results = defaultdict(list)\n",
    "\n",
    "\n",
    "for class_name, trials in all_prompt_activations_with_class.items():\n",
    "    for cluster_id in range(16):  # Assuming you have 16 clusters\n",
    "        cluster_neurons = df.loc[df['cluster'] == cluster_id].index.to_numpy()\n",
    "        num_neurons = len(cluster_neurons)\n",
    "\n",
    "        correlation_sum = 0\n",
    "        for trial in trials:\n",
    "            cluster_activations = trial[cluster_neurons]\n",
    "#             correlation_sum += np.corrcoef(trial, cluster_activations)[0, 1]\n",
    "            correlation_sum += np.mean(cluster_activations)\n",
    "\n",
    "        average_correlation = correlation_sum / len(trials)\n",
    "        correlation_results[class_name].append((cluster_id, num_neurons, average_correlation))\n",
    "\n",
    "# Now let's get top 5 clusters for each class\n",
    "for class_name, correlations in correlation_results.items():\n",
    "    correlations.sort(key=lambda x: x[2], reverse=True)  # Sort by correlation value in descending order\n",
    "    top_5_clusters = correlations[:5]\n",
    "\n",
    "    print(f\"For class {class_name}, the top 5 clusters are:\")\n",
    "    for cluster_id, num_neurons, correlation in top_5_clusters:\n",
    "        print(f\"Cluster ID: {cluster_id}, Number of neurons: {num_neurons}, Mean activation: {correlation}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae1b6262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Lovelace\n",
      "Vincent Van Gogh\n",
      "Princess Leia\n",
      "William Shakespeare\n",
      "Albert Einstein\n",
      "Sherlock Holmes\n",
      "Marie Curie\n",
      "Harry Potter\n",
      "Lady Gaga\n",
      "Isaac Newton\n",
      "Barney the Dinosaur\n",
      "Socrates\n",
      "Cleopatra\n",
      "Hermione Granger\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store dictionaries\n",
    "data = []\n",
    "n_clusters = 16\n",
    "\n",
    "for class_name, trials in all_prompt_activations_with_class.items():\n",
    "    print(class_name)\n",
    "    for trial_id, trial in enumerate(trials):\n",
    "        trial_dict = {'class_id': class_name}\n",
    "        for cluster_id in range(n_cluster):  # Assuming you have 16 clusters\n",
    "            cluster_neurons = df.loc[df['cluster'] == cluster_id].index.to_numpy()\n",
    "\n",
    "            cluster_activations = trial[cluster_neurons]\n",
    "            trial_dict['cluster_' + str(cluster_id)] = np.mean(cluster_activations)  # Add mean activation to the dictionary\n",
    "            \n",
    "        # Append the dictionary to the list\n",
    "        data.append(trial_dict)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "mean_cluster_activations_per_trial = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2770f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            class_id  cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  \\\n",
      "54  Vincent Van Gogh  -7.746094  -4.570312   0.025162  -1.652344  -7.472656   \n",
      "55     Princess Leia  -9.835938  -2.484375   0.027832  -2.628906  -6.992188   \n",
      "56     Princess Leia  -8.218750  -0.486572   0.030640  -2.257812  -6.382812   \n",
      "57     Princess Leia  -9.570312  -1.730469   0.022629  -2.804688  -6.949219   \n",
      "58     Princess Leia  -8.632812  -1.383789   0.020721  -2.425781  -5.832031   \n",
      "59     Princess Leia  -8.265625  -1.383789   0.025436  -1.871094  -6.785156   \n",
      "60     Princess Leia  -8.648438  -1.253906   0.031097  -0.976074  -5.886719   \n",
      "61     Princess Leia -10.593750  -2.443359   0.026123  -2.814453  -6.660156   \n",
      "62     Princess Leia  -7.894531  -1.133789   0.034790  -0.731445  -5.609375   \n",
      "63     Princess Leia  -7.937500  -0.992188   0.029724  -1.014648  -6.179688   \n",
      "64     Princess Leia  -8.429688  -1.458984   0.031372  -0.639648  -6.355469   \n",
      "\n",
      "    cluster_5  cluster_6  cluster_7  cluster_8  cluster_9  cluster_10  \\\n",
      "54   71.81250   0.513184  -1.944336  10.078125  -1.379883    1.077148   \n",
      "55   66.06250   0.393799  -1.537109  11.031250  -1.291016    0.240479   \n",
      "56   57.25000  -0.188477  -1.547852  11.109375  -1.123047    0.355957   \n",
      "57   64.37500   0.209106  -1.374023  10.976562  -1.168945    0.326172   \n",
      "58   59.59375   0.331055  -1.563477  10.789062  -1.210938    0.060577   \n",
      "59   65.81250  -0.233521  -1.622070  10.281250  -1.390625    0.285156   \n",
      "60   63.15625  -0.156982  -1.625000  10.195312  -1.408203    0.363525   \n",
      "61   70.31250   0.204590  -1.606445  10.429688  -1.375000    0.291504   \n",
      "62   62.71875  -0.067261  -1.982422  10.054688  -1.400391    0.299561   \n",
      "63   60.68750  -0.167847  -1.375977   9.796875  -1.297852    0.280762   \n",
      "64   61.34375  -0.293457  -1.448242   9.906250  -1.374023    0.302002   \n",
      "\n",
      "    cluster_11  cluster_12  cluster_13  cluster_14  cluster_15  \n",
      "54    109.2500   17.468750   10.515625   -0.169556    0.143188  \n",
      "55    103.6875   18.203125   11.296875   -0.204712    0.172363  \n",
      "56     92.5000   16.234375   11.437500   -0.191284    0.168335  \n",
      "57     99.6875   18.125000   11.132812   -0.200928    0.163208  \n",
      "58     94.5000   18.421875   10.843750   -0.197510    0.159058  \n",
      "59    102.2500   18.234375   11.828125   -0.172485    0.154175  \n",
      "60     99.1875   18.843750   11.914062   -0.186401    0.159424  \n",
      "61    110.1875   20.375000   11.835938   -0.211182    0.156128  \n",
      "62     95.2500   18.671875   11.625000   -0.179810    0.167725  \n",
      "63     95.0000   18.093750   11.773438   -0.191040    0.163452  \n",
      "64     95.0625   18.515625   11.812500   -0.193848    0.162354  \n"
     ]
    }
   ],
   "source": [
    "print(mean_cluster_activations_per_trial[54:65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3578bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Get unique class IDs\n",
    "class_ids = mean_cluster_activations_per_trial['class_id'].unique()\n",
    "\n",
    "# For each class ID, run a regression\n",
    "for class_id in class_ids:\n",
    "    # Prepare the data\n",
    "    class_df = mean_cluster_activations_per_trial[mean_cluster_activations_per_trial['class_id'] == class_id]\n",
    "    X = class_df.drop('class_id', axis=1)\n",
    "    y = class_df['class_id']\n",
    "\n",
    "    # Add a constant to the predictors\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    # Perform OLS regression\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Display the summary statistics of the regression model\n",
    "    print(f\"Class ID: {class_id}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n-----------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "809ed489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W] [18:23:52.275339] L-BFGS line search failed (code 4); stopping at the last valid step\n",
      "Class ID: Ada Lovelace\n",
      "Intercept: [-6.4875245e-08]\n",
      "Coefficients: [[-6.00275598e-05  1.92644977e-04 -1.97161176e-09 -1.33744747e-04\n",
      "  -2.27602886e-05  4.78152378e-06  1.11343925e-05  2.96447115e-06\n",
      "   1.61020780e-05 -1.08026006e-06  8.65113350e-07  4.80426525e-06\n",
      "   5.18768275e-06  4.08482992e-06  1.72263000e-07 -1.73606125e-07]]\n",
      "Top 5 clusters: [ 1  8  6 12 11]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "[W] [18:23:54.052978] L-BFGS line search failed (code 4); stopping at the last valid step\n",
      "Class ID: Vincent Van Gogh\n",
      "Intercept: [-5.580048e-08]\n",
      "Coefficients: [[-6.0078582e-05  1.9257356e-04 -1.6866875e-09 -1.3373610e-04\n",
      "  -2.2813798e-05  5.3574108e-06  1.1137217e-05  2.9502542e-06\n",
      "   1.6205873e-05 -1.0924251e-06  8.6834223e-07  5.7107059e-06\n",
      "   5.3478343e-06  4.1862841e-06  1.7063915e-07 -1.7221967e-07]]\n",
      "Top 5 clusters: [ 1  8  6 11  5]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Princess Leia\n",
      "Intercept: [-23.316235]\n",
      "Coefficients: [[ 0.22938095  1.7192262  -0.00856358 -1.116296    1.7566779  -0.26831475\n",
      "  -2.4775014  -1.3765179   1.6799556   0.481027    0.44693643  0.23048\n",
      "   0.10415817  0.9345588   0.1972577  -0.07831889]]\n",
      "Top 5 clusters: [ 4  1  8 13  9]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: William Shakespeare\n",
      "Intercept: [0.01000186]\n",
      "Coefficients: [[-2.3831211e-02  1.1729268e-01 -2.0898748e-04  1.5011688e-01\n",
      "   2.4401577e-02  5.7176292e-01  6.9638632e-02 -1.0383862e-01\n",
      "  -3.8967389e-01 -1.3836367e-01 -5.4590359e-02 -4.2985070e-01\n",
      "   3.5506245e-01  6.5791011e-03 -9.0931943e-03  6.9312383e-03]]\n",
      "Top 5 clusters: [ 5 12  3  1  6]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Albert Einstein\n",
      "Intercept: [-0.0029112]\n",
      "Coefficients: [[-0.28803092 -0.12912723 -0.00211833 -0.08638804  0.15305579  0.3494956\n",
      "   0.01559868 -0.19449152  0.05728284 -0.06901234 -0.00982441 -0.23454438\n",
      "  -0.14913097 -0.15976578  0.00280708 -0.00882572]]\n",
      "Top 5 clusters: [ 5  4  8  6 14]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Sherlock Holmes\n",
      "Intercept: [0.10791901]\n",
      "Coefficients: [[-1.1133292  -0.22733212 -0.00617608 -0.11243273  2.4905229  -0.24401821\n",
      "   2.648447   -0.67890406 -0.9491349  -0.31057525  1.3038876   0.1060515\n",
      "  -0.6286264   2.282145    0.05413217  0.05617202]]\n",
      "Top 5 clusters: [ 6  4 13 10 11]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "[W] [18:23:54.491494] L-BFGS line search failed (code 4); stopping at the last valid step\n",
      "Class ID: Marie Curie\n",
      "Intercept: [-5.8857776e-08]\n",
      "Coefficients: [[-6.0067483e-05  1.9259345e-04 -1.7859930e-09 -1.3373580e-04\n",
      "  -2.2793680e-05  5.1961911e-06  1.1146872e-05  2.9539815e-06\n",
      "   1.6195370e-05 -1.0876294e-06  8.6558163e-07  5.4550069e-06\n",
      "   5.3116541e-06  4.1539711e-06  1.7082924e-07 -1.7240912e-07]]\n",
      "Top 5 clusters: [ 1  8  6 11 12]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Harry Potter\n",
      "Intercept: [-0.003932]\n",
      "Coefficients: [[ 4.7279975e-01  2.1375892e-01 -2.1904034e-03  2.0408200e-01\n",
      "   2.2375405e-02 -1.5866125e+00  9.8901361e-01  2.0731827e-02\n",
      "   3.6570203e-01  2.2238554e-01 -1.4751139e-01  9.1873294e-01\n",
      "   6.4198309e-01 -3.5924470e-01 -1.0245903e-03 -1.3741915e-02]]\n",
      "Top 5 clusters: [ 6 11 12  0  8]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Lady Gaga\n",
      "Intercept: [-0.00236736]\n",
      "Coefficients: [[ 0.50271416  0.03536866  0.00289871 -0.13617623 -0.20239122  0.48594993\n",
      "  -0.10173731 -0.17926826  0.01915401  0.13765666 -0.03402344 -0.36823487\n",
      "   0.13611026  0.24745327  0.00333687  0.00942419]]\n",
      "Top 5 clusters: [ 0  5 13  9 12]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "[W] [18:23:54.567126] L-BFGS line search failed (code 4); stopping at the last valid step\n",
      "Class ID: Isaac Newton\n",
      "Intercept: [-6.2975026e-08]\n",
      "Coefficients: [[-6.0037917e-05  1.9262516e-04 -1.9102357e-09 -1.3374310e-04\n",
      "  -2.2763492e-05  4.9297814e-06  1.1148868e-05  2.9565033e-06\n",
      "   1.6164347e-05 -1.0818778e-06  8.6351963e-07  5.0214589e-06\n",
      "   5.2500700e-06  4.1062908e-06  1.7164837e-07 -1.7301220e-07]]\n",
      "Top 5 clusters: [ 1  8  6 12 11]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Barney the Dinosaur\n",
      "Intercept: [0.06039772]\n",
      "Coefficients: [[ 0.31253657  0.10958588  0.00375371  0.14788796 -0.09451795 -0.5827276\n",
      "  -0.02783952  0.30522665  0.8092644  -0.09384589 -0.16629419  0.16510986\n",
      "   0.48531476  0.3569159  -0.01459652  0.0187478 ]]\n",
      "Top 5 clusters: [ 8 12 13  0  7]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Socrates\n",
      "Intercept: [-0.01806762]\n",
      "Coefficients: [[-4.48205233e-01  1.38627648e-01  1.92273554e-04  4.52635109e-01\n",
      "  -5.42392358e-02  2.44365394e-01  1.11971736e-01  9.68255103e-02\n",
      "   3.05653334e-01  4.08217870e-02  1.21271762e-03 -2.24033356e-01\n",
      "   2.34976411e-03 -1.46098331e-01  1.77343655e-02  2.64970469e-04]]\n",
      "Top 5 clusters: [3 8 5 1 6]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Class ID: Cleopatra\n",
      "Intercept: [-0.09080545]\n",
      "Coefficients: [[-0.24039076 -0.0734034  -0.00568322  0.09034029 -0.05377122 -0.07744301\n",
      "   0.3981241   0.5253406   0.62901604  0.25720748  0.07180885  0.11711987\n",
      "  -0.44791543 -0.7396504   0.00860865 -0.02011437]]\n",
      "Top 5 clusters: [ 8  7  6  9 11]\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "[W] [18:23:54.655634] L-BFGS line search failed (code 4); stopping at the last valid step\n",
      "Class ID: Hermione Granger\n",
      "Intercept: [-5.4246012e-08]\n",
      "Coefficients: [[-6.0089831e-05  1.9256376e-04 -1.7015130e-09 -1.3373028e-04\n",
      "  -2.2822116e-05  5.4499092e-06  1.1140464e-05  2.9489020e-06\n",
      "   1.6207245e-05 -1.0948617e-06  8.6883091e-07  5.8834389e-06\n",
      "   5.3786121e-06  4.2043907e-06  1.7004970e-07 -1.7183733e-07]]\n",
      "Top 5 clusters: [ 1  8  6 11  5]\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cuml.linear_model import LogisticRegression\n",
    "import cupy as cp\n",
    "\n",
    "# Get unique class IDs\n",
    "class_ids = mean_cluster_activations_per_trial['class_id'].unique()\n",
    "\n",
    "# For each class ID, run a logistic regression\n",
    "for class_id in class_ids:\n",
    "    # Prepare the data\n",
    "    y = mean_cluster_activations_per_trial['class_id'] == class_id\n",
    "    X = cp.asarray(mean_cluster_activations_per_trial.drop('class_id', axis=1)).astype(cp.float32)\n",
    "    y = cp.asarray(y.astype(int))  # Convert boolean values to int (1 for class of interest, 0 for all others)\n",
    "\n",
    "    # Perform Logistic Regression\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Display the coefficients of the logistic regression model\n",
    "    print(f\"Class ID: {class_id}\")\n",
    "    print(f\"Intercept: {model.intercept_}\")\n",
    "    print(f\"Coefficients: {model.coef_}\")\n",
    "    # print the coefficients in descending order and the corresponding cluster ids\n",
    "    print(f\"Top 5 clusters: {cp.argsort(model.coef_)[0, ::-1][:5]}\")\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-openllm]",
   "language": "python",
   "name": "conda-env-.conda-openllm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
